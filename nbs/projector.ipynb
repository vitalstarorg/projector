{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5d25c3-bf3d-455d-8bac-298809d0555d",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- **Projector** is a studying tool to project the 768 high dimensional vectors onto the 3D space to visualize the tranformation operations through a transformer.\n",
    "- This notebook visualizes how GPT2 transformer transforms a simple prompt through 12 transformer block layers to visualize the production of the predicted token.\n",
    "  - This notebook is showing how to create the visualization on the front page.\n",
    "  - Other results will be posted to demonstrate our studies and the uses of different **projector** features.\n",
    "- The prompt we use is \"Alan Turing theorized that the\", the next token would be \"universe\". The 5 words prompt will be tokenized to 6 tokens prompt as \"theorized\" turns into \"theor\" and \"ized\".\n",
    "- Below we will see two projections.\n",
    "  - First is seeing how each token got transfomed through 12 layers, so the final prediction would be the last 6th token at layer 12. We will see \"universe\" got generated.\n",
    "  - Second is to see the transformation of 6 tokens as a group. This helps to see how the embedding tokens transformed together. So the prediction is shown at the 12th transformation at the 6th token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08cbf7-b0b9-456d-bdf7-5f9f2deb6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "sys.path.append('..')\n",
    "sys.stderr = open('/dev/null', 'w')    # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a48bc4-8225-4cd5-aefc-99eb815fd429",
   "metadata": {},
   "source": [
    "## Embedding Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d212dae-cf82-4c6d-87ab-44794b65e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projector.Projector import Projector\n",
    "from projector.operator.GPT2Operator import GPT2Operator\n",
    "from smallscript import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a301bc2-1e84-4388-9a9f-cfd6648e9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load smallscript 'projector' package\n",
    "sscontext.loadPackage('projector'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8825040-c0ff-4c1a-81dd-1014add05f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Huggingface GPT2 model\n",
    "model = GPT2Operator().name(\"gpt2\").downloadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc5018-b501-46b4-8722-f9a1770a8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Projector instance called 'projector'\n",
    "pj = Projector().name('projector').model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e1f96-83fb-4521-9c3c-8e8894180b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifically select 6 distinct color for each token\n",
    "colorIdx = [1,0,6,7,23,24]\n",
    "colors = [pj.colorShape().defaults()[i] for i in colorIdx]\n",
    "cs = pj.colorShape().clone().colors(colors).reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab23df-c6bd-43ee-a358-705357d721d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the colorband used for each token in the prompt.\n",
    "fig = cs.show()\n",
    "fig.data[0].text = [['Alan','Turing','theor','ized','that','the']]\n",
    "fig.write_image('colorband.png')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27a958-d9fd-492d-8c3e-03955cd4ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 3d projection of 50257 embedded tokens.\n",
    "pj.project();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9437d2a-2370-4a28-aa9c-02657d8a5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the 3d cloud of \n",
    "pj.showEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd8796-08f1-4a48-818f-31175b2d34f3",
   "metadata": {},
   "source": [
    "## Transformer - Token-by-Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823ed91-a00d-428a-9d29-782d29945a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve model parameters\n",
    "nHead = pj.model().modelParams()['n_head'].value()\n",
    "lnfw = pj.model().modelParams().getValue('ln_f.w')\n",
    "lnfb = pj.model().modelParams().getValue('ln_f.b')\n",
    "pj.wOffset(lnfw); pj.bOffset(lnfb);  # lnfw.norm 56.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6d590-8ef9-4ff8-8a31-3fa38f65a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the projected origin\n",
    "pj.clearTraces();\n",
    "prompt = \"Alan Turing theorized that the\"\n",
    "origin = pj.newTrace().name('origin').label('origin').fromVectors(0).color('black').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcaae7-bfa8-4084-9a27-9cbbedc094af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the transformer using an inference object and collect its output\n",
    "# Python: infer.prompt(prompt).wte().wpe().layer(0).layer(1)...layer(11)\n",
    "# Smallscript: infer wte wpe | layer: 0 | layer: 1 | ... | layer: 11\n",
    "vectors = []\n",
    "infer = model.inference().prompt(prompt)\n",
    "wte = infer.ssrun(\"self wte | x\")\n",
    "wpe = infer.ssrun(\"self wpe | x\")\n",
    "for n in range(12):\n",
    "    vector = infer.ssrun(f\"self layer: {n} | x\")\n",
    "    vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2f698-d1c6-4d90-a821-f512eedf0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output vectors as trace\n",
    "twtes = []\n",
    "twpes = []\n",
    "blocks = []\n",
    "for t in range(wte.shape[0]):\n",
    "    twte = pj.newTrace().name(f\"te{t}\").label(f\"te{t}\").color(colors[t]).fromVectors(wte[t])\n",
    "    twtes.append(twte)\n",
    "    twpe = pj.newTrace().name(f\"pe{t}\").label(f\"pe{t}\").color(colors[t]).fromVectors(wpe[t])\n",
    "    twpes.append(twpe)\n",
    "    points = []\n",
    "    for v in vectors:\n",
    "        points.append(v[t])\n",
    "    transitions = torch.stack(points)\n",
    "    trace = pj.newTrace().name(f\"token{t}\").color(colors[t]).fromVectors(transitions).wbnorm()\n",
    "    blocks.append(trace)\n",
    "    pj.nextColor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17956a-cb51-4899-9a81-f227fc2417fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the traces token by token\n",
    "for t in range(wte.shape[0]):\n",
    "    twtes[t].show();\n",
    "    twpes[t].show();\n",
    "    blocks[t].show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc0dc2-5574-43e7-af0e-c27d4a52ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the view as \"cube\" and please align the interactive plot for better viewing angle.\n",
    "vw = pj.getView();\n",
    "vw.aspectmode('cube');\n",
    "pj.updateView(vw);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba5cce-29e8-435a-b935-ad8aa13d1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final result as plot.html\n",
    "pj.figure().write_html('plot.html')\n",
    "\n",
    "# Add the colorband.png\n",
    "with open('plot.html', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "lines.insert(3, \"    <img src='colorband.png'></img>\\n\")\n",
    "with open('plot.html', 'w') as file:\n",
    "    file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1ca98-6da8-4c52-b24d-3dfda125eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the camera is set, let's regenerate each transformation token by token again.\n",
    "for t in range(wte.shape[0]):\n",
    "    twtes[t].remove();\n",
    "    twpes[t].remove();\n",
    "    blocks[t].remove();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5873504-396f-4ac4-abeb-ddfa5a727be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each transformation as an image and combine them as gif\n",
    "pj.figure().write_image(f\"token0.png\");\n",
    "for t in range(wte.shape[0]):\n",
    "    twtes[t].show();\n",
    "    twpes[t].show();\n",
    "    blocks[t].show();\n",
    "    pj.figure().write_image(f\"token{t+1}.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88af8b5-b9a7-4f88-b843-55bab14b0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for t in range(wte.shape[0]+1):\n",
    "    file= f\"token{t}.png\"\n",
    "    image = Image.open(file).convert('RGB')\n",
    "    os.remove(file)\n",
    "    images.append(image)\n",
    "images[0].save('plot.gif', save_all=True, append_images=images[1:], duration=1000, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb69180-c194-4c23-bb68-bfef796404e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the camera and save it as cache project.zip with other internal projector paramaters\n",
    "camera = pj.getCamera()\n",
    "pj.saveCache();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093da01b-349c-4104-80fb-07f05f3af194",
   "metadata": {},
   "source": [
    "## Transformer - Layer-by-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546f652-01da-4ada-8000-6a79ffb3110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new projector\n",
    "pj = Projector().name('projector').model(model)\n",
    "pj.wOffset(lnfw); pj.bOffset(lnfb);  # lnfw.norm 56.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4355a8d-a72b-4c19-af23-b3b0040f1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cached camera and reorient the plot like before\n",
    "pj.loadCache();\n",
    "pj.updateCamera()\n",
    "pj.showEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c96cfc-09f1-4d1b-be6b-09e58c248d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the projected origin\n",
    "layers = []\n",
    "pj.clearTraces();\n",
    "origin = pj.newTrace().name('origin').label('origin').fromVectors(0).color('black').show()\n",
    "layers.append(origin)\n",
    "\n",
    "# Execute the transformer using an inference object and collect its output\n",
    "prompt = \"Alan Turing theorized that the\"\n",
    "infer = model.inference().prompt(prompt)\n",
    "x = infer.ssrun(\"self wte | x\")\n",
    "wte = pj.newTrace().name('te').fromVectors(x)\n",
    "layers.append(wte)\n",
    "x = infer.ssrun(\"self wpe | x\")\n",
    "wpe = pj.nextColor().newTrace().name('pe').fromVectors(x)\n",
    "layers.append(wpe)\n",
    "pj.nextColor();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2bb26-b8b5-4d72-a02c-91df9caa7099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference through layers\n",
    "for n in range(12):\n",
    "    pj.nextColor()\n",
    "    layer = infer.ssrun(f\"self layer: {n} | x\")\n",
    "    trace = pj.newTrace().name(f\"layer{n}\").fromVectors(layer).wbnorm()\n",
    "    layers.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ee9bc-486a-40c2-b7ee-d635be29ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the traces layer by layer\n",
    "for n in range(len(layers)):\n",
    "    layers[n].show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rd_tf3",
   "language": "python",
   "name": "rd_tf3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
